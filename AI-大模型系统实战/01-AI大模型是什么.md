# AI大模型是什么

## AI大模型是什么

### 大模型的定义

学术术语上并没有大模型这个说法，不过它现在被广泛使用，我们也可以这么说无需纠正。学术上更多的使用的是基础模型（foundation model 或 base model），在 2021 年 8 月，李飞飞和其他一百多位学者，联合发布了一份超过 200 页的研究报告  On the Opportunities and Risks of Foundation Models。在这篇文章中，AI 专家们介绍了目前该类模型所面临的机遇和挑战，并一致将这些大模型称为基础模型（Foundation Models），所以通用的标准术语是基础模型而非大模型。

基础模型的特点：它需要兼顾参数量大（大型模型），训练数据量大（大量数据大规模训练）和迁移学习能力强（适应多种下游任务）几点才能够叫做基础模型。

### AIGC

AIGC（Artificial Intelligence Generated Content）称为生成式人工智能，目前全球热门的 AIGC 应用（如 ChatGPT，Midjourney）几乎都是通过“大模型”的上下文学习、涌现和思维链等能力支撑实现的，所以大众和媒体往往会把这种“智能”和“大模型”技术建立一一映射的关系。因此讨论 AIGC 应用时，各类媒体往往会在“生成式人工智能”后面加上“大模型”，这也就是我们常听到的“生成式人工智能大模型”。

涌现：在大模型领域，当模型突破某个规模时，性能显著提升，表现出让人惊艳、意想不到的能力。

思维链（Chain-of-thought，CoT）指的是通过一系列有逻辑关系的思考步骤，形成一个完整的思考，进而得出答案的过程。

## 大模型技术由来

模型的参数规模开始急剧增长，模型变得越来越大。

训练数据的规模也发生了质的飞跃。在更大规模的训练数据基础上，以计算能力和存储成本的降低为有利条件，模型的参数规模再次急剧增加，模型变得更大了。

AI 大模型正在使用全网的数据进行无监督训练，我们进入了一切皆为训练数据的时代。这使得模型可以获得几乎无限的训练数据。为了对如此规模的数据进行建模，模型参数的规模越大越好，因此模型变得越来越大了。

总结：AI大模型的发展和全网知识的共享，计算能力和存储成本的降低紧密相关。

## 大模型火起来的原因

1. 展现出了出色的涌现、思维链和上下文学习的能力，不再停留在“人工智障”的阶段，极大地提升了自然语言理解和生成的能力
2. 跨模态建模能力的发展。这让同一个模型能像人类一样同时理解和处理 Excel、PPT、PDF、图像和视频等多种形式的数据。加持了这样的能力，算法生成的信息量从此发生质变，生成式人工智能发挥作用的舞台就更多了。
3. 生成式模型的交互方式。生成式 AI 产品巧妙地利用了人类的惰性，通过新的交互方式，大大提高了产品的渗透率。这使得人们不断地使用 ChatGPT，并逐渐产生了依赖。这也成为了当前 AI 大模型产业，迅速发展的关键点。

**所有这些前提条件的实现，都依赖于存储和计算能力的持续发展**

## AI 大模型能做什么

可以很好地应对如语言翻译、创意策划、文章创作和代码编写这类任务。

但是也有一些局限性，比如训练数据存在时效性的问题，GPT-4 Turbo 使用了 2023 年 4 月之前的训练数据，无法评判那之后的事实，同时大模型在因果推断方面也存在一些问题。

在处理数据时可能会表现出一些“幻觉”(hallucination)。这种现象通常发生在模型在没有明确事实依据的情况下生成了错误或虚构的信息。通常原因是训练数据包含了错误、歧义或虚构的信息。模型的设计和参数设置可能会影响其在处理某些任务时的表现。例如，如果模型的目标函数过于侧重于生成流畅、有吸引力的文本，而不够重视准确性和事实依据，那么模型可能会倾向于生成更多的虚构或错误信息。 这些“幻觉”通常会在模型缺乏足够的上下文信息或在面对模棱两可的问题时显得更为严重。例如，在你提到的“林黛玉倒拔垂杨柳”这个例子中，由于模型可能从未接触过正确的信息，所以可能会基于其训练数据中的某些片段错误地生成了这个故事。 对于专业或技术性的主题，这种现象可能会影响模型提供的建议和信息的准确性。为了避免或减轻这种“幻觉”，在与模型交互时提供清晰、准确和具体的上下文信息是非常重要的。同时，也可以通过引入外部验证或人工审核的过程来确保得到准确和可靠的信息。

