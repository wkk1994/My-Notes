# AI大模型是什么

## AI大模型是什么

### 大模型的定义

在学术术语上没有大模型这个说法，不过现在被广泛使用，可以不用纠正。学术上的标准术语是基础模型。基础模型的定义是一种大型机器学习模型，通常在大量数据上进行大规模训练（通过监督学习或半监督学习），以使它可以适应各类下游任务。

基础模型的特点：它需要兼顾**参数量大**（大型模型），**训练数据量大**（大量数据大规模训练）和**迁移学习能力强**（适应多种下游任务）几点才能够叫做基础模型。

**总结特点就是数据大、参数大、任务多**

### AIGC

AIGC（Artificial Intelligence Generated Content）称为生成式人工智能，目前热门的 AIGC 应用（如 ChatGPT，Midjourney）几乎都是通过“大模型”的上下文学习、涌现和思维链等能力支撑实现的，所以大众和媒体往往会把这种“智能”和“大模型”技术建立一一映射的关系。因此讨论 AIGC 应用时，各类媒体往往会在“生成式人工智能”后面加上“大模型”，这也就是我们常听到的“生成式人工智能大模型”。

涌现：在大模型领域，当模型突破某个规模时，性能显著提升，表现出让人惊艳、意想不到的能力。

思维链（Chain-of-thought，CoT）指的是通过一系列有逻辑关系的思考步骤，形成一个完整的思考，进而得出答案的过程。

## 大模型技术由来

大模型的“大”是一个相对概念，是一个持续的过程。更大规模的训练数据需要模型具备更强的记忆、理解和表达能力。而为了拥有更强的记忆、理解和表达能力，模型则需要更大的参数量，也就是更大的模型。

模型越来越大的原因：内因就是存储和算力的发展；外因是人类知识量和共享度上的发展，互联网技术使得知识共享加速，知识体量快速膨胀。

## 大模型火起来的原因

1. 能力的提升：大型语言模型展现出了出色的涌现、思维链和上下文学习的能力，不再停留在“人工智障”的阶段，极大地提升了自然语言理解和生成的能力。
2. 跨模态建模能力的发展：这让同一个模型能像人类一样同时理解和处理 Excel、PPT、PDF、图像和视频等多种形式的数据。加持了这样的能力，算法生成的信息量从此发生质变，生成式人工智能发挥作用的舞台就更多了。
3. 生成式模型的交互方式：生成式 AI 产品巧妙地利用了人类的惰性，通过新的交互方式，大大提高了产品的渗透率。这使得人们不断地使用 ChatGPT，并逐渐产生了依赖。这也成为了当前 AI 大模型产业，迅速发展的关键点。

**所有这些前提条件的实现，都依赖于存储和计算能力的持续发展**

## AI 大模型能做什么

可以很好地应对如语言翻译、创意策划、文章创作和代码编写这类任务。

但是也有一些局限性，比如训练数据存在时效性的问题，GPT-4 Turbo 使用了 2023 年 4 月之前的训练数据，无法评判那之后的事实，同时大模型在因果推断方面也存在一些问题。

### 大模型的问题

**幻觉**

在处理数据时可能会表现出一些“幻觉”(hallucination)。这种现象通常发生在模型在没有明确事实依据的情况下生成了错误或虚构的信息。通常原因是训练数据包含了错误、歧义或虚构的信息。模型的设计和参数设置可能会影响其在处理某些任务时的表现。例如，如果模型的目标函数过于侧重于生成流畅、有吸引力的文本，而不够重视准确性和事实依据，那么模型可能会倾向于生成更多的虚构或错误信息。 这些“幻觉”通常会在模型缺乏足够的上下文信息或在面对模棱两可的问题时显得更为严重。例如，在你提到的“林黛玉倒拔垂杨柳”这个例子中，由于模型可能从未接触过正确的信息，所以可能会基于其训练数据中的某些片段错误地生成了这个故事。 对于专业或技术性的主题，这种现象可能会影响模型提供的建议和信息的准确性。为了避免或减轻这种“幻觉”，在与模型交互时提供清晰、准确和具体的上下文信息是非常重要的。同时，也可以通过引入外部验证或人工审核的过程来确保得到准确和可靠的信息。

**数据时效性**

**输入长度限制**

**内容可信度**
