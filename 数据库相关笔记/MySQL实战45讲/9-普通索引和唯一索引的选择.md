# 普通索引和唯一索引的选择

## 查询过程

```sql
select id from T where k=5
```

查询语句在索引树上查找的过程，先是通过 B+ 树从树根开始，按层搜索到叶子节点，也就是数据页，然后可以认为数据页内部通过二分法来定位记录。

* 对于普通索引，查找满足的第一个记录后，需要查找下一个记录，直到碰到第一个不满足条件的记录为止。
* 对于唯一索引，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。

**两者的区别：**

微乎其微，InnoDB 的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在 InnoDB 中，每个数据页的大小默认是 16KB。
普通索引，当找到第一个满足条件的记录后，会相对唯一索引多做“查找和判断下一条记录”的操作，最糟糕的情况是当前条件位于数据页的尾部，需要再读取下一个数据页，但是这个概率很低。所以这个对于CPU来说可以忽略不计。


## 更新过程

### change buffer是什么？

当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。

change buffer，实际上它是可以持久化的数据。

将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 `merge`。除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。

change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%

**merge 的执行流程是这样的：**

1. 从磁盘读入数据页到内存（老版本的数据页）；
2. 从 change buffer 里找出这个数据页的 change buffer 记录 (可能有多个），依次应用，得到新版数据页；
3. 写 redo log。这个 redo log 包含了数据的变更和 change buffer 的变更。

到这里 merge 过程就结束了。这时候，数据页和内存中 change buffer 对应的磁盘位置都还没有修改，属于脏页，之后各自刷回自己的物理数据，就是另外一个过程了。

**change buffer 的使用场景：**

change buffer 只限于用在普通索引的场景下，而不适用于唯一索引。在一个数据页做 merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。

所以适用于写多读少的业务中。页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。

对于一个业务更新后马上会做查询，那么就会触发merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。

### 更新过程

* 对于唯一索引，所有的更新操作都需要先判断是否违反唯一性约束。就需要将对应的数据页读入内存中才能判断，如果已经在内存中就直接判断，更新内存就会很快，就没必要使用 change buffer。

* 对于普通索引，更新操作会判断对应的数据页是否在内存中，如果在内存中直接更新，不在内存将更新记录在 change buffer。

**两者的区别：**

唯一索引，当记录要更新的目标页不在内存中，就需要将数据从磁盘读入内存，涉及随机 IO 的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。特别地，在使用机械硬盘时，change buffer 这个机制的收效是非常显著的。

### change buffer 和 redo log

redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。

## 是否使用唯一索引

* 首先，业务正确性优先。咱们这篇文章的前提是“业务代码已经保证不会写入重复数据”的情况下，讨论性能问题。如果业务不能保证，或者业务就是要求数据库来做约束，那么没得选，必须创建唯一索引。这种情况下，本篇文章的意义在于，如果碰上了大量插入数据慢、内存命中率低的时候，可以给你多提供一个排查思路。

* 然后，在一些“归档库”的场景，你是可以考虑使用普通索引的。比如，线上数据只需要保留半年，然后历史数据保存在归档库。这时候，归档数据已经是确保没有唯一键冲突了。要提高归档效率，可以考虑把表里面的唯一索引改成普通索引。

## MySQL为什么会选错索引

通过命令`explain`可以查看当前查询的执行情况：

```sql
explain select * from index_temp where a between 10000 and 20000; 
```

### 优化器的逻辑

优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的 CPU 资源越少。

语句`select * from test where a < 50`
如果查询的结果集大于等于总行数的25%，并且需要回表，优化器会走id索引，进行全表查询，不会走where中的索引a

当然，扫描行数并不是唯一的判断标准，优化器还会结合是否使用临时表、是否排序等因素进行综合判断。

**统计信息：** 

这个统计信息就是索引的“区分度”，一个索引上不同的值越多，这个索引的区分度就越好，一个索引上不同值得个数称为“基数”（cardinality），基数越大，索引区分度越好。

查看统计信息：`show index from index_temp`；

在统计信息中索引的基数都是不准确的，MySQL使用采用统计的方法。因为把整张表取出来一行行统计，虽然可以得到精确的结果，但是代价太高了，所以只能选择“采样统计”。

采样统计的时候，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。而数据表是会持续更新的，索引统计信息也不会固定不变。所以，当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计。

在 MySQL 中，有两种存储索引统计的方式，可以通过设置参数 innodb_stats_persistent 的值来选择：
* 设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10。
* 设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。

`analyze table t`以用来重新统计索引信息。

**扫描行数是怎么判断的？**
  
MySQL在真正开始执行语句之前，并不能精确的知道满足这个条件的记录有多少条。而只能根据统计信息来估算记录数。

通过命令`explain`可以查看当前查询的大致扫描的行数。

**优化器为什么放着扫描 行少的执行计划不用，却选择了扫描行数多的执行计划呢？**

这是因为查询语句不单单返回主键字段时，都要回到主键索引上查出整行数据，这个代价优化器也要算进去的。优化器会估算这两个选择的代价，从结果看来，优化器认为直接扫描主键索引更快。当然，从执行时间看来，这个选择并不是最优的。

语句：
```sql
mysql> select * from t where (a between 1 and 1000)  and (b between 50000 and 100000) order by b limit 1;
```
按照常理，应该选择索引a，因为索引a只扫描1001行就可以了，但是MySQL优化器还是选择了索引b。

#### 索引选择异常和处理

* 采用 `force index(index_name)` 强行选择一个索引

    MySQL 会根据词法解析的结果分析出可能可以使用的索引作为候选项，然后在候选列表中依次判断每个索引需要扫描多少行。如果 force index 指定的索引在候选索引列表中，就直接选择这个索引，不再评估其他索引的执行代价。
    `select * from t force index(a) where (a between 1 and 1000)  and (b between 50000 and 100000) order by b limit 1;`
* 修改语句，引导 MySQL 使用我们期望的索引。

    在上面的例子中，把“order by b limit 1” 改成 “order by b,a limit 1” ，语义的逻辑是相同的。但是优化器会选择索引a。

* 在有些场景下，可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。

## 字符串字段上添加索引

* 直接创建完整索引，这样可能比较占用空间；

* 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；

* 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题，不支持范围扫描；

* 创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。

## 为什么索引字段查询不使用索引

对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。

### 条件字段函数操作

```sql
select count(*) from tradelog where month(t_modified)=7;
```

对于索引的字段`t_modified`进行函数操作之后再查询，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。需要注意的是，优化器并不是要放弃使用这个索引。而是放弃了树搜索功能，所以进行了全表扫描。

### 隐式类型转换

对于本来是varchar类型的字段，查询时使用int查询，需要进行类型转换。

* 不同的数据库类型转换的规则不同，可以通过`select “10” > 9 `结果分析类型转换规则：
  * 如果规则是“将字符串转成数字”，那么就是做数字比较，结果应该是 1；
  * 如果规则是“将数字转成字符串”，那么就是做字符串比较，结果应该是 0。
  * MySQL是将字符串转成数字进行比较，对于不能转成数字的默认转成0。

对于语句`select * from tradelog where tradeid=110717;`如果`tradeid`是字符串类型，那么语句相当于`select * from tradelog where  CAST(tradid AS signed int) = 110717;`这条语句触发了上面说到的规则：对索引字段做函数操作，优化器会放弃走树搜索功能。

对于语句`select * from tradelog where id="83126";`id是int类型，优化器还是会走树搜索。

### 隐式字符编码转换

对于关联查询如果关联的两张表编码不同，当驱动表的字符集大于被驱动表时，被驱动表的关联字段上的索引不会走树搜索，所以被驱动表会做全表扫描。反之驱动表的字符集小于等于被驱动表的，被驱动表的索引正常执行。

对于查询语句`select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2;`（tradelog字符集utf8mb4，trade_detail字符集utf8）相当于`select d.* from tradelog l, trade_detail d where CONVERT(d.traideid USING utf8mb4)=l.tradeid and l.id=2;`

### 查询字符串超长

查询语句`select * from table_a where b='1234567890abcd';`
对于字段`b`定义为varchar(10)查询条件`1234567890abcd`虽然超出了定义长度，但是MySQL还是会将`1234567890abcd`截取前10位去匹配，将匹配结果的`b`字段值再与`1234567890abcd`比较。还是会扫描行。

## 问题

* **如果是针对非唯一索引和唯一索引的更新和delete而且条件是where 索引值=这种情况,
是否二级索引和唯一索引就没有区别呢**

    这时候要“先读后写”，读的时候数据会读入内存，更新的时候直接改内存，就不需要change buffer了。没有区别，只有在insert的时候才会有区别（猜测）。

* **change buffer 一开始是写内存的，那么如果这个时候机器掉电重启，会不会导致 change buffer 丢失？**

    1.change buffer有一部分在内存有一部分在ibdata.
做purge操作,应该就会把change buffer里相应的数据持久化到ibdata。

    2.redo log里记录了数据页的修改以及change buffer新写入的信息
如果掉电,持久化的change buffer数据已经purge,不用恢复。

    主要分析没有持久化的数据
情况又分为以下几种:

    (1)change buffer写入,redo log虽然做了fsync但未commit,binlog未fsync到磁盘,这部分数据丢失

    (2)change buffer写入,redo log写入但没有commit,binlog以及fsync到磁盘,先从binlog恢复redo log,再从redo log恢复change buffer

    (3)change buffer写入,redo log和binlog都已经fsync.那么直接从redo log里恢复。