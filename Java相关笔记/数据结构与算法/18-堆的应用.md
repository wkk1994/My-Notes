# 堆的应用

## 优先级队列

队列的最大特征是先进先出，而在优先级队列中，数据的出队顺序不是按照先进先出，而是按照优先级来，优先级最高的，最先出队。

**如何实现一个优先级队列？**

实现优先级队列的方式有多种，但是使用堆来实现是最直接、最高效的。这是因为，堆和优先级队列非常相似。一个堆就可以看作一个优先级队列。往优先级队列中插入一个元素，就相当于往堆中插入一个元素；从优先级队列中取出优先级最高的元素，就相当于取出堆顶元素。

优先级队列的应用场景很多，比如，赫夫曼编码、图的最短路径、最小生成树算法等等。不仅如此，很多语言中，都提供了优先级队列的实现，比如，Java 的 PriorityQueue，C++ 的 priority_queue 等。

### 1.合并有序小文件

假设有100个小文件，每个文件的大小是100MB，每个文件存储的都是有序的字符串，希望把这100个小文件合并成一个有序的大文件。这里就可以使用优先级队列实现。

思路：从100个文件中，各取第一个字符串，放入到小顶堆中，那么堆顶的元素，也就是优先级队列队首的元素，就是最小的字符串。将这个字符串放入到大文件中，并将其从堆中删除。然后再从小文件中取出下一个字符串（再取下一个字符串是从刚刚堆顶的字符串对应的小文件中获取），放入到堆中。循环这个过程，就可以将100个小文件中的数据一次放入到大文件中。

### 2.高性能定时器

假设有一个定时器，定时器中维护了很多定时任务，每个任务都设定了一个要触发执行的时间点。定时器每过一个很小的单位时间（比如 1 秒），就扫描一遍任务，看是否有任务到达设定的执行时间。如果到达了，就拿出来执行。

![定时器示例](https://static001.geekbang.org/resource/image/b0/e7/b04656d27fd0ba112a38a28c892069e7.jpg)

但是，这样每过 1 秒就扫描一遍任务列表的做法比较低效，主要原因有两点：第一，任务的约定执行时间离当前时间可能还有很久，这样前面很多次扫描其实都是徒劳的；第二，每次都要扫描整个任务列表，如果任务列表很大的话，势必会比较耗时。

可以使用优先级队列来解决这些问题。按照任务设定的执行时间，将这些任务存储在优先级队列中，队列首部（也就是小顶堆的堆顶）存储的是最优先执行的任务。

这样定时器就不需要每隔一秒就扫描一遍任务列表了。它拿队首任务的执行时间点，与当前时间点相减，得到一个时间间隔 T。这个时间间隔 T 就是，从当前时间开始，需要等待多久，才会有第一个任务需要被执行。这样，定时器就可以设定在 T 秒之后，再来执行任务。从当前时间点到（T-1）秒这段时间里，定时器都不需要做任何事情。

当 T 秒时间过去之后，定时器取优先级队列中队首的任务执行。然后再计算新的队首任务的执行时间点与当前时间点的差值，把这个值作为定时器执行下一个任务需要等待的时间。这样，定时器既不用间隔 1 秒就轮询一次，也不用遍历整个任务列表，性能也就提高了。

## 利用堆求Top K

求Top K的问题抽象成两类。一类是针对静态数据集合；另一类是针对动态数据集合。

针对静态数据，如何在一个包含n个数据的数组中，查找前K大的数据？可以维护一个大小为K的小顶堆，顺序遍历数组，从数组中取出数据与堆顶元素比较，如果比堆顶元素大，就将堆顶元素删除，并将这个数据插入到堆中；如果比堆顶元素小不做处理，继续遍历数组。这样等数组中的数据都遍历完之后，堆中的数据就是前K大数据了。

遍历数组需要 O(n) 的时间复杂度，一次堆化操作需要 O(logK) 的时间复杂度，所以最坏情况下，n 个元素都入堆一次，时间复杂度就是 O(nlogK)。

针对动态数据求Top K就是实时Top K。如果每次询问前K大数据，都基于当前的数据重新计算的话，那时间复杂度就是O(nlogK)，n表示当前数据的大小。实际上，可以一直维护一个K大小的小顶堆，当有数据被添加到集合中时，就拿它与堆顶的元素对比。如果比堆顶元素大，就把堆顶元素删除，并且将这个元素插入到堆中；如果比堆顶元素小，则不做处理。这样，无论任何时候需要查询当前的前 K 大数据，都可以立刻返回。

## 利用堆求中位数

求中位数，如果数据的个数是奇数，把数据从小到大排列，那第n/2 + 1个数据就是中位数（注意：假设数据是从0开始编写的）；如果数据的个数是偶数的话，那处于中间位置的数据有两个，第n/2个和第n/2 + 1个数据，这个时候可以随意取一个。

对于一个**静态数据**，中位数是固定的，可以先排序，第n/2个数据就是中位数。每次查询中位数时，直接返回这个固定值就可以了。

对于一个**动态数据**，中位数不停地变动，如果再用先排序的方法，每次查找中位数的时候都需要先排序，那效率就不高了。可以借助堆这种数据结构，不用排序，就可以高效地实现中位数操作。

实现方式是，维护两个堆，一个大顶堆，一个小顶堆。大顶堆中存储前半部分数据，小顶堆中存储后半部分数据，且小顶堆中的数据都大于大顶堆中的数据。也就是说，如果有 n 个数据，n 是偶数，从小到大排序，那前 n/2 个数据存储在大顶堆中，后 n/2​ 个数据存储在小顶堆中。这样，大顶堆中的堆顶元素就是要找的中位数。如果 n 是奇数，情况是类似的，大顶堆就存储 n/2​+1 个数据，小顶堆中就存储 n/2​ 个数据。

![通过堆查找中位数示例](https://static001.geekbang.org/resource/image/08/99/08c29d3e014a4baf5f8148c2271e6099.jpg)

因为是动态数据，所以如果新加入的数据小于等于大顶堆，就将这个数据插入到大顶堆；否则将这个数据插入到小顶堆。这个时候可能出现，两个堆中的数据个数不符合前面约定的情况：如果 n 是偶数，两个堆中的数据个数都是 2n​；如果 n 是奇数，大顶堆有 2n​+1 个数据，小顶堆有 2n​ 个数据。这个时候，可以从一个堆中不停地将堆顶元素移动到另一个堆，通过这样的调整，来让两个堆中的数据满足上面的约定。

![动态数据堆调整](https://static001.geekbang.org/resource/image/ae/b1/aee4dcaf9d34111870a1d66a6e109fb1.jpg)

这样，利用一个大顶堆和一个小顶堆，实现了再动态数据集合中求中位数的操作。插入数据因为需要涉及堆化，所以时间复杂度是O(logn)，但是求中位数只需要返回大顶堆的堆顶元素就可以了，时间复杂度是O(1)。

## 快速求接口的 99% 响应时间

利用两个堆不仅可以快速求出中位数，还可以快速求其他百分位的数据，原理类似。例如快速求接口的99%响应时间。

什么是“99% 响应时间”：中位数的概念就是将数据从小到大排列，处于中间位置，就叫中位数，这个数据会大于等于前面 50% 的数据。99 百分位数的概念可以类比中位数，如果将一组数据从小到大排列，这个 99 百分位数就是大于前面 99% 数据的那个数据。那么对应的“99% 响应时间”就是，在接口响应时间中，按照时间从小到大排列，它的99百分位数对应的响应时间就是“99% 响应时间”。

总结：如果有 n 个数据，将数据从小到大排列之后，99 百分位数大约就是第 n\*99% 个数据，同类，80 百分位数大约就是第 n*80% 个数据。

**如何求 99% 响应时间？**

维护两个堆，一个大顶堆，一个小顶堆。假设当前总数据的个数是n，大顶堆中保存n*99%个数据，小顶堆中保存n\*1%个数据。大顶堆堆顶的数据就是要找的99%响应时间。但是为了保持大顶堆中的数据占99%，小顶堆中的数据占1%，在每次插入数据之后，都要重新计算，这个时候大顶堆和小顶堆的数据个数，是否还符合99:1这个比例。如果不符合，需要将一个堆中的数据移动到另一个堆，直到满足这个比例。

通过这样的方法，每次插入数据，可能会涉及几个数据的堆化操作，所以时间复杂度是 O(logn)。每次求 99% 响应时间的时候，直接返回大顶堆中的堆顶数据即可，时间复杂度是 O(1)。

## 有一个包含 10 亿个搜索关键词的日志文件，如何快速获取到 Top 10 最热门的搜索关键词呢？

处理这个问题，有很多高级的解决方法，比如使用 MapReduce 等。但是，如果我们将处理的场景限定为单机，可以使用的内存为 1GB。那这个问题该如何解决呢？

因为用户搜索的关键词，有很多可能都是重复的，所以我们首先要统计每个搜索关键词出现的频率。我们可以通过散列表、平衡二叉查找树或者其他一些支持快速查找、插入的数据结构，来记录关键词及其出现的次数。

假设我们选用散列表。我们就顺序扫描这 10 亿个搜索关键词。当扫描到某个关键词时，我们去散列表中查询。如果存在，我们就将对应的次数加一；如果不存在，我们就将它插入到散列表，并记录次数为 1。以此类推，等遍历完这 10 亿个搜索关键词之后，散列表中就存储了不重复的搜索关键词以及出现的次数。

然后，我们再根据前面讲的用堆求 Top K 的方法，建立一个大小为 10 的小顶堆，遍历散列表，依次取出每个搜索关键词及对应出现的次数，然后与堆顶的搜索关键词对比。如果出现次数比堆顶搜索关键词的次数多，那就删除堆顶的关键词，将这个出现次数更多的关键词加入到堆中。以此类推，当遍历完整个散列表中的搜索关键词之后，堆中的搜索关键词就是出现次数最多的 Top 10 搜索关键词了。

但是如果10亿条搜索关键词中不重复的有1亿条，如果每个关键词的平均长度是50个字节，那存储1亿个关键词最起码需要5GB的内存空间，而散列表因为要避免频繁冲突，不会选择太大的装载因子，所以消耗的内存空间就更多了。这个时候可以使用之前讲过的哈希算法，相同数据经过哈希算法得到的哈希值是一样的。我们可以根据哈希算法的这个特点，将 10 亿条搜索关键词先通过哈希算法分片到 10 个文件中。

具体可以这样做：我们创建 10 个空文件 00，01，02，……，09。我们遍历这 10 亿个关键词，并且通过某个哈希算法对其求哈希值，然后哈希值同 10 取模，得到的结果就是这个搜索关键词应该被分到的文件编号。对这 10 亿个关键词分片之后，每个文件都只有 1 亿的关键词，去除掉重复的，可能就只有 1000 万个，每个关键词平均 50 个字节，所以总的大小就是 500MB。1GB 的内存完全可以放得下。我们针对每个包含 1 亿条搜索关键词的文件，利用散列表和堆，分别求出 Top 10，然后把这个 10 个 Top 10 放在一块，然后取这 100 个关键词中，出现次数最多的 10 个关键词，这就是这 10 亿数据中的 Top 10 最频繁的搜索关键词了。

## 问题

* 有一个访问量非常大的新闻网站，希望将点击量排名 Top 10 的新闻摘要，滚动显示在网站首页 banner 上，并且每隔 1 小时更新一次。如何来实现呢？

  如果只是求一个小时内的top10，可以将一小时内的浏览量日志取出，先遍历获取每个新闻摘要的访问次数。然后维护一个top10的小顶堆，遍历之前的访问次数，插入到堆中，最后就能获得top10。如果日志量很大，也可以想上面的做法一样，通过哈希算法分成多个小文件处理。

  如果是求之前总计访问量的top10，还需要加上之前的访问量。