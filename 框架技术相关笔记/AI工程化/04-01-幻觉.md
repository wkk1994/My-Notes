# 幻觉出现的原因与解决方式

## 一、幻觉出现的原因

幻觉产生的原因，可以从模型→检索→增强→生成→用户五个层面来足步分析：

1. **模型本身的局限**
   - 语言模型是概率生成器，本质是“预测下一个词”，而不是知识库。
   - 当缺乏相关知识或训练数据时，模型会“编造”合理但错误的信息。

2. **检索层面的缺陷**
   - **召回失败**：检索不到相关文档（embedding 不准确、召回率低）。
   - **检索结果噪声**：检索到了不相关或干扰性较强的文本。
   - **文档切分不当**：chunk 太小丢失语义，太大超出上下文。

3. **增强环节的问题**
   - Prompt 拼接不合理，导致模型没能利用好检索到的上下文。
   - 检索到的内容覆盖度不足（少量 context 无法支撑完整回答）。

4. **生成环节的偏差**
   - 模型在上下文不足时，会凭语言模式“脑补”答案。
   - 解码策略（如 temperature 过高）导致模型更倾向于“自由发挥”。

5. **用户输入的复杂性**
   - 问题模糊/开放性太强，检索结果难以精准匹配。
   - 多跳问题（需要跨文档推理），模型容易编造连接。

---

## 二、解决幻觉的方式
### 1. 模型层面
- **使用更强大的 LLM**：更大的模型往往在事实一致性上更好。  
- **微调 / Instruction Tuning**：在特定领域数据上训练，减少随意编造。  
- **约束生成**：如限制输出格式、引入 schema（结构化输出）。  

### 2. 检索层面
- **改进 Embedding**：用更强的向量模型（如 OpenAI text-embedding-3，或者领域特化的 embedding）。  
- **混合检索**：向量检索 + BM25 关键词检索，互补优劣。  
- **Reranking**：用更强的重排序模型过滤掉无关内容（如 Cohere Rerank）。  
- **优化 Chunking**：句子级、段落级结合，设置合理 overlap。  

### 3. 增强环节
- **Prompt Engineering**：明确告诉模型“只基于上下文回答”，“若未找到答案则说不知道”。  
- **Context 压缩与扩展**：把多个检索结果总结后再传给 LLM，减少噪声。  
- **多文档合成**：对每个检索结果单独问答，再合并，避免模型过度“脑补”。  

### 4. 生成约束
- **低温采样（temperature ↓）**：减少模型“发挥”的自由度。  
- **引用溯源**：强制模型在答案中标注出处，提高可验证性。  
- **工具调用**：遇到事实类问题时让模型调用 API / 数据库，而不是自己回答。  

### 5. 用户交互层面
- **澄清问题**：让模型先复述/确认用户问题，避免误解。  
- **迭代问答**：复杂问题分解成子问题（multi-hop retrieval）。  

---

## 三、实践上的组合方案
通常不会只用一种手段，而是几种方式组合：
1. **检索增强**：Hybrid Retrieval + Rerank，提升召回准确性。  
2. **Prompt 约束**：让 LLM 遵循“只基于检索结果回答”。  
3. **引用机制**：让 LLM 输出答案 + 参考片段，便于校验。  
4. **Fallback 策略**：若检索结果为空，直接回答“无相关信息”。  
5. **多阶段问答**：分解复杂问题，逐步推理，降低错误率。  

## 四、实践中的坑

1. 模型层：微调≠一定降低幻觉
– 现象：用领域 QA 对做 SFT 后，模型对“训练集里没出现过的问法”幻觉反而↑。
– 原因：微调把分布压得太窄，OOD 问题触发“自由发挥”。
– 解法：
• 保留 5 %～10 % 通用指令数据做“正则化”。
• 采用 LoRA + 高 learning-rate decay，别让模型“死记硬背”。

2. 检索层：Embedding 没问题，但“时间切片”导致召回失效
– 场景：财报/法规类知识库，2022 vs 2024 两份文件几乎同名。
– 如果只按 top-k 向量返回，很容易把“过期条款”当真理。
– 解法：
• 在 metadata 里显式写入“生效日期”，用“时间权重” rerank（简单到 elasticsearch 里加个 decay function 即可）。
• 让 LLM 在 Prompt 里看到“知识截止日期”字段，再做判断。

3. 生成层：引文对了，内容却“移花接木”
– 现象：模型把 A 文档的数字套到 B 文档的结论上，看上去“有出处”，实则偷梁换柱。
– 解法：
• 强制“逐句引用”：在 Prompt 里要求「每句事实型陈述必须带 chunk_id，且只能使用对应 chunk 的原文」。
• 后处理加“一致性校验”脚本：用 NLI 模型判断“句子是否被 chunk 文本蕴含”，不通过就打回重写。