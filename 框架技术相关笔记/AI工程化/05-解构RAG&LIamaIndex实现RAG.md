# 解构RAG&LIamaIndex实现RAG

## LLM应用的局限性

* 幻觉：LLM输出与事实不符或没有来源的错误信息。
* 上下文长度限制：注意力稀释
* 知识限制（领域知识不足）：LLM的知识来源于预训练，而这些数据主要来自互联网上的公开语料及人类历史上积累的公共信息。
* 数据安全

RAG的本质是在问题上嵌入提示词，这个提示词来自我们提前预设的一些文档中。

> 幻觉出现的原因
> 注意力稀释？

## RAG的定义

RAG（）检索增强生成结合了传统信息检索技术和最新的生成模型，从大型知识库中检索与查询最相关的信息，基于重排序的信息生成回答。

> RAG是一种解决方案，解决LLM应用的局限性。

## RAG VS 微调

补充纬度的表格

• 减少幻觉
• 知识获取
• 知识时效
• 模型定制
• 可解释性
• 计算资源
• 延迟要求

微调更想是一个黑盒，RAG是白盒所以有可解释性

## RAG的基本模型与工作过程

## RAG的五个经典阶段

* 加载
  加载的时候会额外把文件的名称和地址也放入，原因是不信任大模型的输出，需要给出参考的文档。
* 索引
  目前都是通过向量进行索引
* 存储
  现在的存储方式除了向量数据库，还有其他比如ES等多种方式。
* 查询
  检索的过程通常用两种方式，一种是通过向量数据库查找语义相识的内容，一种是直接按照问题匹配相识的内容。
* 评估

索引阶段可以做的事情：定时监控文件是否变更，如果变更就刷新索引

加载：
* 节点：不容的容器
连接器：解析不同的文档

什么时候用RAG、什么时候用Fine-tuning
朴素RAG&进阶RAG和模块化RAG

## RAG评估

### 检索评估

* 纯检索指标：问题和结果的关系
  * 精准率
  * 召回率
  * F1分数

* 检索&重排指标
  * 平均倒数排名
  * 平均精确率均值
  * 归一化折损累计增益

### 生成评估

生成结果评估
- Correctness：比较生成的答案与标准答案
- Relevance：答案是否与 query 相关
- Logic：答案逻辑性
- Style：生成风格评估，长短、语气等

生成阶段评估（除了第一个会用到，其他的也不会用到，即使用了也没法解决？）
- Fathfulness（Answer to Context Retrieved）
- 噪声鲁棒性 (Noise Robustness) 
- 否定拒绝 (Negative Rejection)
- 信息整合 (Info Integration) 
- 反事实鲁棒性 (Counterfactual Robustness)

## RAG实现

* QAnything 代码最简单，其中用了LangChain实现
* Llamaindex 代码工整，可以作为参考自己实现RAG功能

QAnything、Dify、Ragflow
Llamaindex、LangChain

> FastAPI：python web框架
> Gradio：python生成页面