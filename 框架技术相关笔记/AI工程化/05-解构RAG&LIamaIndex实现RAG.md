# 解构RAG&LIamaIndex实现RAG

## LLM应用的局限性

* 幻觉：LLM输出与事实不符或没有来源的错误信息。
* 上下文长度限制：注意力稀释
* 知识限制（领域知识不足）：LLM的知识来源于预训练，而这些数据主要来自互联网上的公开语料及人类历史上积累的公共信息。
* 数据安全

RAG的本质是在问题上嵌入提示词，这个提示词来自我们提前预设的一些文档中。

> 幻觉出现的原因
> 注意力稀释？

## RAG的定义

RAG（）检索增强生成结合了传统信息检索技术和最新的生成模型，从大型知识库中检索与查询最相关的信息，基于重排序的信息生成回答。

> RAG是一种解决方案，解决LLM应用的局限性。

## RAG VS 微调

补充纬度的表格

• 减少幻觉
• 知识获取
• 知识时效
• 模型定制
• 可解释性
• 计算资源
• 延迟要求

微调更想是一个黑盒，RAG是白盒所以有可解释性

## RAG的基本模型与工作过程

## RAG的五个经典阶段

* 加载
  加载的时候会额外把文件的名称和地址也放入，原因是不信任大模型的输出，需要给出参考的文档。
* 索引
  目前都是通过向量进行索引
* 存储
  现在的存储方式除了向量数据库，还有其他比如ES等多种方式。
* 查询
  检索的过程通常用两种方式，一种是通过向量数据库查找语义相识的内容，一种是直接按照问题匹配相识的内容。
* 评估

索引阶段可以做的事情：定时监控文件是否变更，如果变更就刷新索引