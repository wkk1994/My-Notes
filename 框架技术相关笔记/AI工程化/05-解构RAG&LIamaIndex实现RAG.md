# 解构RAG&LIamaIndex实现RAG

## LLM应用的局限性

* 幻觉：LLM输出与事实不符或没有来源的错误信息。
* 上下文长度限制：注意力稀释
* 知识限制（领域知识不足）：LLM的知识来源于预训练，而这些数据主要来自互联网上的公开语料及人类历史上积累的公共信息。
* 数据安全

RAG的本质是在问题上嵌入提示词，这个提示词来自我们提前预设的一些文档中。

> [幻觉出现的原因](./05-01-幻觉.md)
> [注意力稀释](./05-02-注意力稀释.md)

## RAG的定义

RAG（Retrieval-Augmented Generation，检索增强生成）检索增强生成结合了传统信息检索技术和最新的生成模型，从大型知识库中检索与查询最相关的信息，基于重排序的信息生成回答。

> RAG是一种解决方案，解决LLM应用的局限性。

## RAG VS 微调
# RAG vs 微调 对比表

| 维度   | RAG        | 微调                  | 结论                 |
| ---- | ------------- | --------------------- | -----------------------|
| 减少幻觉 | 借助检索获得外部知识，幻觉减少，但依赖检索质量。   | 通过在目标语料上学习，减少领域内幻觉，但对超出语料范围的问题易出错。 | 如果检索质量高，RAG 在减少幻觉上更具优势；微调在闭域内效果更稳。 |
| 知识获取 | 可直接通过检索调用外部知识库，灵活扩展。       | 需要重新训练或增量训练才能注入新知识。                | RAG 在知识获取和扩展性上更灵活，微调适合固定领域知识的沉淀。   |
| 知识时效 | 更新知识库即可实时更新模型“认知”。         | 模型需重新训练，更新周期长，成本高。                 | RAG 更适合需要频繁更新知识的场景；微调适合知识稳定的任务。    |
| 模型定制 | 通过提示工程 + 检索策略，有限定制化，个性化较弱。 | 可在数据层面深度定制，嵌入特定风格或行为。              | 微调在深度定制方面更强；RAG 适合快速搭建和轻量定制。比如想让模型“说人话+表情包”：微调 500 条对话就能内嵌；RAG 改 prompt 容易“出戏”。       |
| 可解释性 | 检索到的文档可溯源，解释性强。            | 输出基于模型参数内部权重，难以解释来源。               | RAG 在可解释性上更优。                      |
| 计算资源 | 主要消耗在检索和向量库维护，训练成本低。       | 微调需要 GPU 资源和大量算力，存储不同版本模型也占用空间。    | RAG 更节省训练资源；微调需更强算力。               |
| 延迟要求 | 检索引入额外延迟，响应速度可能受影响。（+50~200 ms 检索）        | 推理速度快（与原生模型一致），无额外检索延迟。            | 微调在延迟敏感场景中更优，RAG 在延迟可接受范围内优势明显。    |

**选型指南**

* 事实问答、法规、财报、医疗——先上 RAG，幻觉率才能压到合规线。
* 品牌话术、角色扮演、格式强约束——用微调，把风格“焊死”进权重。
* 资源/时效双杀的场景（既要实时又要定制），“RAG + 轻量 LoRA”混部：新事实走 RAG，语气走 LoRA，业界 2025 年主流方案。

> 微调更像是一个黑盒，RAG是白盒所以有可解释性

## RAG的基本模型与工作过程

![图 RAG工作过程](https://raw.githubusercontent.com/wkk1994/image-repository/main/2025-09/RAG%E5%B7%A5%E4%BD%9C%E8%BF%87%E7%A8%8B.png)  

## RAG的五个经典阶段

* 加载
  加载的时候会额外把文件的名称和地址也放入，原因是不信任大模型的输出，需要给出参考的文档。
* 索引
  目前都是通过向量进行索引
* 存储
  现在的存储方式除了向量数据库，还有其他比如ES等多种方式。
* 查询
  检索的过程通常用两种方式，一种是通过向量数据库查找语义相识的内容，一种是直接按照问题匹配相识的内容。
* 评估

索引阶段可以做的事情：定时监控文件是否变更，如果变更就刷新索引

加载：
* 节点：不容的容器
连接器：解析不同的文档

什么时候用RAG、什么时候用Fine-tuning
朴素RAG&进阶RAG和模块化RAG

## RAG评估

### 检索评估

* 纯检索指标：问题和结果的关系
  * 精准率
  * 召回率
  * F1分数

* 检索&重排指标
  * 平均倒数排名
  * 平均精确率均值
  * 归一化折损累计增益

### 生成评估

生成结果评估
- Correctness：比较生成的答案与标准答案
- Relevance：答案是否与 query 相关
- Logic：答案逻辑性
- Style：生成风格评估，长短、语气等

生成阶段评估（除了第一个会用到，其他的也不会用到，即使用了也没法解决？）
- Fathfulness（Answer to Context Retrieved）
- 噪声鲁棒性 (Noise Robustness) 
- 否定拒绝 (Negative Rejection)
- 信息整合 (Info Integration) 
- 反事实鲁棒性 (Counterfactual Robustness)

## RAG实现

* QAnything 代码最简单，其中用了LangChain实现
* Llamaindex 代码工整，可以作为参考自己实现RAG功能

QAnything、Dify、Ragflow
Llamaindex、LangChain

> FastAPI：python web框架
> Gradio：python生成页面