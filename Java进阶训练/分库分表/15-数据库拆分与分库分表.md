# 数据库拆分与分库分表

## 1.为什么要做数据库拆分*

### 单机数据库已经无法适应互联网的发展

随着业务非飞速发展，数据规模极速膨胀，单机数据库无法适应业务的发展。

从性能来说，关系型数据库大多采用B+树类型的索引，在数量超过一定阀值的情况下，索引深度的增加会使得磁盘访问IO次数的增加，导致查询性能下降。高并发的请求同时落到一个集中式的数据库上，也会导致系统瓶颈。

从可用性来说，集中式的数据库压力越来越大，简单的主从架构难以承担。数据库的备份和恢复的时间成本也会随着数据量的增多的增大，主从延迟可能会越来越高，主从延迟越高读写分离越不可用。

数据量过大可能产生的问题：

* 无法执行DDL，比如添加一列，或者增加索引，都会直接影响线上业务，导致长时间的数据库无响应。
* 无法备份，备份会自动 lock 数据库的所有表，然后导出数据量大了就没法执行了。
* 影响性能与稳定性，系统越来越慢，随时可能会出现主库延迟高，主从延迟很高，且不可控，对业务系统有极大的破坏性影响。

### 从读写分离到数据库拆分

主从架构解决了高可用，读扩展，但是单机的容量是不变的，单机写性能无法解决。
通过分库分表的方式，将原先集中式的数据库分为多个数据库集群提供服务，可以降低单个数据库的写压力，提升数据库的整体容量上限。

### 扩展立方体

定义项目/系统的扩展模型，项目/系统的演进过程只能按照这个方向进行扩展。

* X轴（水平轴）：通过clone整个系统复制，集群。
  就是将系统进行集群部署，比如mysql的主从复制。
* Y轴（垂直轴）：通过解耦不同的功能复制，业务拆分。
  将原先的单体应用进行拆分，变成微服务的形式。
* Z轴（纵深轴）：通过拆分不同的数据扩展，数据分片。
  将原先的整个表的数据进行分库分表。

### 数据库/数据的扩展

全部数据 --> 数据复制 --> 主从结构、备份与高可用：解决了数据库的高可用，分担了读压力。
业务分类数据 --> 垂直分库分表 --> 分布式服务化、微服务：解决了部分的读写压力，提升了数据库容量。
任意数据 --> 水平分库分表 --> 分布式结构、任意扩容：解决读写压力，提升数据库容量。

## 2.数据库垂直拆分*

### 垂直拆分-以淘宝的服务化为例

淘宝早期的架构模式是一个单体应用，将用户服务相关的操作封装成jar，打包到不同的应用中，每个应用需要访问用户服务的时候使用这个jar，相当于每个应用都要维护访问用户数据库的连接，数据库要支持更大的连接数。

现在进行拆分，通过垂直分库分表，将应用分布式服务化，最终走向微服务架构。将应用拆分次成用户中心、订单中心、交易中心，每个应用提供RPC接口访问，这样每个应用都不需要直接访问其他的数据库，只访问自己业务的数据库。提高服务的复用，减轻数据库的压力。

### 拆库

垂直拆分（拆库）：将一个数据库，拆分成多个提供不同处理能力的数据库。

例如：将订单和产品相关的数据拆分成两个独立的数据库，这种拆分方式对业务影响大，需要修改业务代码，原来的关联查询也不能使用了。举例说：原先查询订单信息会通过关联查询将产品信息一并获取，拆库后，需要在查询订单信息后，调用产品信息提供的RPC接口，获取产品信息，然后再在业务代码中进行处理，一并返回。

### 拆表

垂直拆分（拆表）：对于单表的数据量过大（或字段过多）的表，可能对单表进行拆分。

例如：一个200列的订单主表，拆分成十几个子表：订单表、订单详情表、订单收件信息表、订单产品快照表等等。这个对业务系统的影响有时候可能会大到跟新作一个系统差不多。所以，我们一般情况下，尽量少用这种办法。

### 不同规模公司的数据库模式

大公司模式：

* 正常的业务数据走mysql；
* 大规模的查询搜索使用solr/ES；
* 数据跑批，业务分析使用大数据（hbase），如果数据跑批后需要回流，再写回到mysql。

小公司模式：一个mysql打天下。

### 垂直拆分的优缺点

优点：

* 单库（单表）变小，便于管理和维护
* 对性能和容量有所提升
  原先单库存储所有的数据，现在分成多个库，容量自然提升了。
* 改造后，系统和数据的复杂度降低
  每个系统只操作的自己业务相关的表，不需要惯性其他业务的操作，业务复杂度降低。
* 可以做为微服务改造的基础
  按照业务进行垂直拆分，同时业务系统的边界也清晰了，应用可以按照这个进行业务拆分。

缺点：

* 库（表）变多，管理变复杂
  对于拆表的来说，原先修改数据只需要修改单表就可以了，现在需要修改多个表才能让数据变一致性。
* 对业务系统有较强的侵入性
  进行垂直拆分后，原先的系统不能在单库中完成所有操作，业务代码需要修改，调用其他业务的接口。
* 改造过程复杂，容易出故障
  垂直拆分后，相关联的系统都需要修改，容易引入新问题。
* 拆分到一定程度就不能进行拆分
  比如：订单业务，拆库后，订单信息和子订单信息是需要同时操作的，不能再将订单信息和子订单信息再进行拆库。

### 垂直拆分的一般做法

* 1.梳理清除拆分范围和影响范围；
* 2.检查评估和改造（重构）影响到的服务；
* 3.准备新的数据库集群复制数据；
* 4.修改系统配置并发布新版上线。

**⚠️注意：**

* 先拆分系统，还是先拆分数据库？
* 先拆分多大范围？
  事先分析拆分后对数据库产生的影响，如果一次拆分后，只能拆分百分之几的数据，那么除非是试点拆分（一次怕拆分太多影响很大，逐步小系统开始拆分），否则这样拆分没有意义，拆分出来的数据量太小。

**这些问题是在拆分前一定要分析清楚的。**

## 3.数据库水平拆分*

### 水平拆分

水平拆分就是直接对数据进行分片，有分库和分表两个具体方式，但是都是只降低单个节点的数据量，不改变数据本身的结构。这样对于业务系统来说，就不需要做很大的改动，甚至可以基于一些中间件做到透明。

水平分库分表，分为：分库不分表、分表不分库、分库分表三类。

区别：只分表不分库，不能提升数据库的容量上限。如果分库不分表，分库都是在一个数据库实例上，实际效果和分表不分库差不多。

### 水平拆分的方式

* 按主键分库分表
  通过id取模，将数据保存到不同的库表中。
  举例：将一个10亿条记录的订单单库单表，按照用户id除以32取模，把单库拆分成32个库orderDB_00..31；再按订单 id 除以 32 取模，每个库里再拆分 成 32 个表t_order_00..31。这样一共是 1024 个子表，单个表的数据量就只是 10 万条了。**一个查询如果能够直接路由到某个具体的子表，那么查询效率就会很高。但是如果对于不能确定某个子表，就需要到每个表中进行查询，如果有1024个子表，就需要执行1024个查询。如果有大量高并发的请求，这样的查询就有性能问题。**
  如果订单表是使用买家id进行分库分表，那么根据买家id进行查询的时候可以直接定位子表。但是如果要使用卖家id去查询订单的信息，就需要广播，这个时候可以通过维护一个异构的数据，通过卖家id进行分库分表。这个使用卖家id分库分表的数据通过同步的机制同步订单表的信息，这种方式阿里和京东都在使用。

* 按时间分库分表
  数据有时间属性时，可以按照时间进行分库分表。
  举例：数据信息分为当前信息和历史信息，可以按照季度、月、天来划分到不同的表中，这样当按照时间纬度来查询数据时，就可以直接定位到当前的这个子表。

* 强制按照条件指定分库分表：比如配置好某些用户对应的子表，其他的用户走默认的处理。

* 自定义方式分库分表：指定某些条件的数据进入到某些库或表。

常见的还是按照主键或时间进行分库分表。

**为什么有些DBA不建议分表，只建议分库？（一些中间件，也只支持分库，不能分表）**

* 分表不能解决数据库容量和io问题。
* 只是分库可以使用单数据库服务模拟分库。

### 分库还是分表，如何选择

一般情况下，如果数据库的读压力比较大，磁盘IO成为瓶颈，那么分库比分表要好。如果数据库的容量不是很大，只是单表的数据量很大，影响了读的性能，可以选择分表。**一般的时候优先考虑使用分库。**

### 分库分表的优缺点

优点：

* 解决容量问题
* 比垂直拆分对系统影响小
  可以使用中间件的方式，消除对系统的影响
* 部分提升性能和稳定性
  分库分表后读写请求也对应的分散到不同的数据库上，提升了读写的性能。

缺点：

* 集群规模大，管理复杂
  需要更多的机器部署数据库，可能并不是问题，机器永远比人便宜。
* 复杂SQL支持问题（业务侵入性、性能）
  对于关联查询可能需要业务代码进行修改。
* 数据迁移问题
  需要将数据插入到不同的表中。
* 一致性问题
  对于有一致性问题的表，建议使用同一个分表规则，比如订单表，订单详情表使用订单号最为分表规则，这样同一个订单的订单表和订单详情表都在一个数据库中，没有一致性问题。

### 数据的分类管理

根据数据使用的可能性进行分类：热数据（使用可能性很大）、温数据（可能会使用）、冷数据（使用可能性很少）、冰数据（不会再使用）。

对于不同类型的数据进行不同的处理：

* 热数据：同时放到数据库和内存中。
* 温数据：提供正常的查询操作。
* 冷数据：从数据库删除，归档到一些便宜的磁盘，用压缩的方式（比如 MySQL 的 tokuDB 引擎，可以压缩到几十分之一）存储，用户需要邮件或者提交工单来查询，我们导出后发给用户；
* 冰数据：备份到磁带之类的介质上，不提供任何查询操作。

## 4.相关的框架和中间件*

Java框架层面：

* TDDL（已经闭源）
* Apache ShardingSphere-JDBC，只能Java语言使用。

它们的实现方式都是在应用端设置分库分表的规则，然后在应用执行sql的时候，解析sql，根据配置的分库分表的规则，将sql语句改写成对应的子表进行执行。

中间件层面：

* DRDS（商业闭源），可以看作是TDDL上演化过来的。
* Apache ShardingSphere-Proxy
* MyCat/DBLE
* Cobar
* Vitness
* KingShard

中间件可以看做是一个mysql服务，它代理了其他的mysql服务，在它上面配置分库分表的规则。系统直接访问中间件，中间件会通过分库分表的规则，将sql解析成对应的子表，最后进行执行。好处是对应用系统透明，对任意的语言都可以使用。

**使用中间件的好处是对应用系统透明，不需要修改应用系统。**

### 数据库中间件的技术演进

摩尔定律失效

分布式崛起（CAP）

可以妥协实现打折的CAP，比如保证系统99.999%的一致性，对于剩下的不一致性，通过监控，自动或手动去解决不一致的数据。

![数据库技术的演进](https://note.youdao.com/yws/api/personal/file/WEB251b09275dbea6df4b811477240b5126?method=download&shareKey=4a864c3f6105bcfca653d216b9049148)

市面上99%在使用类库/框架进行分库分表；0.9%的人在使用数据库中间件进行分库分表；0.09%的人使用分布式数据库。
为什么？使用不同的分库分表的方式，需要的决策不同。引入一个类库，只需要程序员进行决策就可以；引入数据库中间件，需要运维人员或者dba进行决策；引入分布式数据库，需要更高的领导进行决策，比如技术总监等。

### 数据库中间件ShardingSphere

Apache ShardingSphere 是一套开源的分布式数据库中间件解决方案组成的生态圈，它 由 JDBC、Proxy 和 Sidecar（规划中）这 3 款相互独立，却又能够混合部署配合使用的 产品组成。 它们均提供标准化的数据分片、分布式事务和数据库治理功能，可适用于如 Java 同构、异构语言、云原生等各种多样化的应用场景。

* 框架 ShardingSphere-JDBC

* 中间件 ShardingSphere-Proxy

## 5.如何做数据迁移

数据迁移是分库分表中最重要的一步。主要的问题：

* 怎么能平滑的迁移旧数据到新的数据库和系统。
* 特别是在异构的数据库结构情况下。
* 数据库迁移要保证数据准确，迁移速度快，减少停机时间，做到对业务的影响最小。

### 数据迁移的方式：全量

全量数据导出导入

* 1.业务系统停机
* 2.数据迁移，校验一致性
  数据迁移过程中，索引或唯一约束可以在迁移完成后添加，这样性能高些。
  数据的校验包括：数据数量，表数等是否一致的校验。校验方式，可以通过给数据添加指纹，通过指纹校验是否一致校验数据的一致性，单个数据进行校验太慢，可以通过分片的方式同时进行。

* 3.然后业务系统升级，接入新数据库

如果使用的是中间件的方式分库分表，可以dump后全量导入，中间件进行分库分表控制。（如果是）异构数据，需要用程序来处理。

优点：迁移方式简单，不容易有问题，适用于数据量比较小的系统，停机时间比较短。
缺点：对于大数据量的迁移，停机时间太长，影响业务。

### 数据迁移的方式：全量+增量

依赖于数据本身的时间戳

* 先同步数据到最近的某个时间戳
* 然后发布升级时停机维护
* 再同步最后一段时间（通常是一天）的变化数据
* 最后升级业务系统，接入新数据库
* 同步数据操作和全量的一样需要校验数据。

优点：减少了停机时间，相对简单。
缺点：停机时间还是相对较长。

> 小公司常用的方式

### 数据迁移的方式：binlog+全量+增量

* 通过主库或者从库的binlog来解析和重新构造数据，实现复制。
* 一般需要中间件等工具的支持。

可以实现多线程、断点续传、全量历史数据和增量数据同步。
进而可以做到：

* 自定义复杂异构数据结构；
* 实现自动扩容和缩容，比如分库分表到单库单表，单库单表到分库分表，分4个库表到分64个库表。

优点：停机时间很短，甚至做到不停机，在某次业务停机时再进行新数据库的接入。
缺点：实现比较复杂。

### 迁移工具 ShardingSphere-scaling

* 支持数据全量和增量同步。
* 支持断点续传和多线程数据同步。
  会将同步作业写入到zk上，在重启时，获取zk的数据，继续工作。
* 支持数据库异构复制和动态扩容。
* 具有UI界面，可视化配置。

## Tips

> mysql的io模型
> 数据孤岛、数据仓库、数据集市、数据湖
> 数据治理，DAMA
> 成熟的方法论有三个：架构：TOGAF；项目：PMP；数据：DAMA。
> 人力的六大模块
> 什么是目标和愿景、口号
> CICD、滚动、灰度、蓝绿、金丝雀发布。
> 分布式事务：互联网一般使用不多，互联网金融会使用的多一点
> partition
